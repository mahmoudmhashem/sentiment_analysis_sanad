{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7211b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f119bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_dir(data_dir):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for class_dir in os.listdir(data_dir):\n",
    "        class_dir_pth = os.path.join(data_dir, class_dir)\n",
    "        print(f\"working on {class_dir} ...\")\n",
    "        n_files = len(os.listdir(class_dir_pth))\n",
    "        for i, document in enumerate(os.listdir(class_dir_pth)):\n",
    "            document_pth = os.path.join(class_dir_pth, document)\n",
    "            with open(document_pth, encoding=\"UTF-8\") as f:\n",
    "                lines = f.readlines()\n",
    "                x_data.append(lines[1])\n",
    "                y_data.append(class_dir)\n",
    "            print(f\"{int(100 * i / n_files)} %\", end='\\r')\n",
    "    print(\"done!\")\n",
    "#     df = pd.DataFrame(data=text, columns=[\"text\"])\n",
    "#     df[\"class\"] = text_class\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3de9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on Culture ...\n",
      "working on Finance ...\n",
      "working on Medical ...\n",
      "working on Politics ...\n",
      "working on Religion ...\n",
      "working on Sports ...\n",
      "working on Tech ...\n",
      "done!\n",
      "working on Culture ...\n",
      "working on Finance ...\n",
      "working on Medical ...\n",
      "working on Politics ...\n",
      "working on Religion ...\n",
      "working on Sports ...\n",
      "working on Tech ...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"E:\\Technical\\Electro pi\\SANAD_ Single-Label Arabic News Articles Dataset for Automatic Text Categorization\\SANAD_SUBSET\\khaleej\"\n",
    "train_data_dir = os.path.join(data_dir, \"Train\")\n",
    "test_data_dir = os.path.join(data_dir, \"Test\")\n",
    "\n",
    "x_train, y_train = read_data_from_dir(train_data_dir)\n",
    "x_test, y_test = read_data_from_dir(test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f14fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cleaned = map(gensim.utils.simple_preprocess, x_train)\n",
    "x_test_cleaned = map(gensim.utils.simple_preprocess, x_test)\n",
    "\n",
    "x_train_cleaned = np.array(list(x_train_cleaned), dtype=object)\n",
    "x_test_cleaned = np.array(list(x_test_cleaned), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57438f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")\n",
    "\n",
    "model.build_vocab(x_train_cleaned, progress_per=1000)\n",
    "\n",
    "model.train(x_train_cleaned, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "model.save(\"word2vec-SANAD-khaleej-arabic-language.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03624c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vect(text):\n",
    "    text_vect = np.zeros(100)\n",
    "    for word in text:\n",
    "        try:\n",
    "            text_vect += model.wv[word]\n",
    "        except KeyError:\n",
    "            text_vect += np.zeros(100)\n",
    "    return text_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd567a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cleaned_vec = map(text2vect, x_train_cleaned)\n",
    "x_test_cleaned_vec = map(text2vect, x_test_cleaned)\n",
    "\n",
    "x_train_cleaned_vec = np.array(list(x_train_cleaned_vec))\n",
    "x_test_cleaned_vec = np.array(list(x_test_cleaned_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec1a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0a9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(x_train_cleaned_vec, y_train)\n",
    "\n",
    "y_train_pred = svc.predict(x_train_cleaned_vec)\n",
    "y_test_pred = svc.predict(x_test_cleaned_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922883f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.9658608058608059\n",
      "tseting_accuracy: 0.9586813186813187\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "tseting_accuracy  = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"training_accuracy: {training_accuracy}\")\n",
    "print(f\"tseting_accuracy: {tseting_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c1fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
